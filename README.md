# Graph Learning

## Why Graph Learning?

Graphs are powerful data structures that can represent complex relationships and interactions between entities. Graph learning techniques allow us to extract meaningful information from graphs, discover patterns, and make predictions.

## Graph Properties

- **Directed Graphs**: Graphs where edges have a direction (from one node to another).
- **Weighted Graphs**: Graphs where edges have associated weights or values.
- **Connected Graphs**: Graphs where there is a path between any two nodes.
- **Types of Graphs**: Examples include social networks, recommendation systems, knowledge graphs, etc.

## Graph Concepts

- **Objects**: Nodes or vertices in the graph.
- **Graph Measures**: Metrics to quantify properties of the graph (e.g., degree centrality, betweenness centrality).
- **Adjacency Matrix**: A matrix representation of the graph.
- **Breadth-First Search (BFS)**: Traversal technique to explore nodes level by level.
- **Depth-First Search (DFS)**: Traversal technique to explore nodes as deeply as possible.

## Nodes and Deep Walk

- **Word2Vec**: A popular embedding technique for representing nodes in a graph.
- **CBOW vs. Skip-gram**: Two variants of Word2Vec.
- **Skip-gram Model**: A neural network architecture for learning node embeddings.
- **Deep Walk and Random Walk**: Techniques to generate node sequences for training embeddings.

Feel free to explore more about graph learning and apply these concepts to your specific use cases!

